{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GTHA housing market database\n",
    "# OSEMN methodology Step 2: Scrub\n",
    "# Step 2.3 addition of new attributes to the Teranet dataset\n",
    "\n",
    "---\n",
    "\n",
    "This notebook describes Step 2.3 (part of _Step 2: Scrub_ of OSEMN methodology) performed on the Teranet dataset.\n",
    "\n",
    "Step 2.3 focuses on the addition of several new attributes to the Teranet dataset. Plan for the addition of the new attributes is presented below.\n",
    "\n",
    "Previous steps included: \n",
    "\n",
    "* **Step 2.1:** spatial join between the Teranet points and the polygons of GTHA Dissemination Areas (DAs)\n",
    "    \n",
    "    * During step 2.1, Teranet records whose coordinates fall outside of the GTHA boundary (as defined by the DA geometry) have been filtered out (6,803,691 of the original 9,039,241 Teranet records remain in the dataset)\n",
    "     \n",
    "    * In addition to that, three new columns (`OBJECTID`, `DAUID`, and `CSDNAME`) derived from DA attributes have been added to each Teranet transaction\n",
    "\n",
    "    * for details, see `notebooks/2.scrub/2.1_teranet_gtha_spatial_join.ipynb`\n",
    "\n",
    "* **Step 2.2:** correction for consistency of the Teranet records\n",
    "\n",
    "    * column names were converted to lower case\n",
    "    \n",
    "    * inconsistent capitalizations were fixed for columns\n",
    "    \n",
    "        * `municipality`    \n",
    "        * `street_name`\n",
    "        * `street_designation`\n",
    "        * `postal_code` (did not show problems, converted as a preventive measure)\n",
    "        \n",
    "    * columns `province` and `street_suffix` were removed from the dataset\n",
    "    \n",
    "    * new column `street_name_raw` was created: reserve copy of unmodified `street_name`\n",
    "    \n",
    "    * column `street_name` was parsed and cleaned for:\n",
    "    \n",
    "        * `postal_code`\n",
    "        * `unitno`\n",
    "        * `street_number`\n",
    "        * `street_direction`\n",
    "        * `street_designation`\n",
    "        \n",
    "    * plots of the count and percentage of missing values per column were produced\n",
    "    \n",
    "    * inconsistent entries were fixed in the following columns:\n",
    "        \n",
    "        * `street_direction`\n",
    "        * `street_designation`\n",
    "        * `municipality`\n",
    "        * `street_name`\n",
    "        * `unitno`\n",
    "        \n",
    "    * for details, see `notebooks/2.scrub/2.2_teranet_consistency.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "For description of OSEMN methodology, see `methodology/0.osemn/osemn.pdf`.\n",
    "\n",
    "For background information, description of the Teranet dataset, and its attributes, see `methodology/1.obtain/obtain.pdf`.\n",
    "\n",
    "For description of _Step 2: Scrub_ of OSEMN methodology, see `methodology/2.scrub/scrub.pdf`.\n",
    "\n",
    "For description of the cleanup plan for the Teranet dataset, see `methodology/2.scrub/teranet_cleanup_plan.pdf`.\n",
    "\n",
    "For description of Step 2.1 of the cleanup process, see `notebooks/2.scrub/2.1_teranet_gtha_spatial_join.ipynb`.\n",
    "\n",
    "For description of Step 2.2 of the cleanup process, see `notebooks/2.scrub/2.2_teranet_consistency.ipynb`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plan for the addition of the new attributes\n",
    "\n",
    "### Previously added attributes\n",
    "\n",
    "Previously, the following new attributes were created in the Teranet dataset:\n",
    "\n",
    "* attributes produced from the spatial join with DA geometry:\n",
    "\n",
    "    * `objectid`: an identifier for Dissemination Areas (DAs), added as a backup identifier for DAs\n",
    "\n",
    "    * `dauid`: another identifier for Dissemination Areas, indented to be used as the **_foreign key_** linking Teranet records with DAs (will become the **_primary key_** of DA-level datasets (_e.g.,_ DA-level Census data)\n",
    "    \n",
    "    * `csdname`: municipality name according to Census data (DA-level)\n",
    "\n",
    "These attributes were added to each Teranet record via a spatial join of Teranet points with the polygons of Dissemination Areas (DAs) during Step 2.1 of the cleanup process\n",
    "\n",
    "* attributes produced during the correction of Teranet records for consistency:\n",
    "\n",
    "    * `street_name_raw`: unmodified reserve copy of the original `street_name` from the Teranet dataset\n",
    "\n",
    "### Attributes to be added in this step\n",
    "\n",
    "In this step, the following attributes will be added to the Teranet dataset:\n",
    "\n",
    "* surrogate key:\n",
    "\n",
    "    * `transaction_id`: unique identifier for each Teranet transaction \n",
    "    \n",
    "Essentially, a simple range index, which represents the row number of a record in the full Teranet dataset (filtered to include only GTHA records), ordered by date (from earliest to latest) and `pin`\n",
    "    \n",
    "* attributes for display\n",
    "\n",
    "    * `date_disp`: `registration_date` converted to `datetime.date` data type to exclude the timestamp (original `registration_date` is stored in NumPy's `datetime64` format to allow more efficient datetime operations)\n",
    "    \n",
    "    * `price_disp`: `consideration_amt` formatted to include thousands separator (_e.g.,_ '3,455,122') and stored as a string, for display purposes\n",
    "    \n",
    "* attributes for record grouping\n",
    "    \n",
    "    * `year`: year parsed from `registration_date`, to simplify record grouping\n",
    "    \n",
    "    * `3year`: `registration_date` parsed for 3-year intervals (_e.g.,_ '2014-2016'), to simplify record grouping\n",
    "    \n",
    "    * `5year`: `registration_date` parsed for 5-year intervals (_e.g.,_ '2012-2016'), to simplify record grouping\n",
    "    \n",
    "    * `10year`: `registration_date` parsed for 3-year intervals (_e.g.,_ '2007-2017'), to simplify record grouping\n",
    "    \n",
    "    * `xy`: `x` and `y` coordinates concatenated together (_e.g.,_ '43.098324_-79.234235'), can be used to identify and group records by their coordinate pairs\n",
    "    \n",
    "* correction of `consideration_amt` for inflation    \n",
    "    \n",
    "    * `price_infl`: `consideration_amt` corrected for inflation\n",
    "    \n",
    "* exploratory attributes\n",
    "\n",
    "    * `pin/xy_total_sales`: total records for this `pin`/`xy`\n",
    "\n",
    "    * `pin/xy_prev_sales`: previous records from this `pin`/`xy` (not counting current transaction)\n",
    "\n",
    "    * `pin/xy_price_cum_sum`: cumulative price of all records to date from this `pin`/`xy`\n",
    "\n",
    "    * `pin/xy_price_pct_change`: price percentage change compared to previous record from this `pin`/`xy`\n",
    "\n",
    "    * `price_da_pct_change`: price percentage change compared to previous record from this DA (by `da_id`)\n",
    "\n",
    "    * `pin/xy_years_since_last_sale`: years since last sale from this `pin`/`xy`\n",
    "\n",
    "    * `da_days_since_last_sale`, `da_years_since_last_sale`: days or years since last sale from this DA (by `da_id`)\n",
    "\n",
    "    * `sale_next_6m/1y/3y`: \"looks into the future\" to see whether there is another transaction from this `pin`/`xy` within the given time horizon (6 months, 1 year, 3 years)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['Teranet_consistent.csv', 'Teranet_with_DA_cols.csv', 'HHSaleHistory.csv']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "data_path = '../../data/teranet/'\n",
    "os.listdir(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Teranet data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "----- DataFrame loaded\nin 21.15 seconds (0.35 minutes)\nwith 6,803,691 rows\nand 17 columns\n-- Column names:\n Index(['lro_num', 'pin', 'consideration_amt', 'registration_date',\n       'postal_code', 'unitno', 'street_name', 'street_designation',\n       'street_direction', 'municipality', 'street_number', 'x', 'y',\n       'objectid', 'dauid', 'csdname', 'street_name_raw'],\n      dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df = pd.read_csv(data_path + 'Teranet_consistent.csv',\n",
    "                 parse_dates=['registration_date'], low_memory=False)\n",
    "elapsed = time() - t\n",
    "print(\"----- DataFrame loaded\"\n",
    "      \"\\nin {0:,.2f} seconds ({1:.2f} minutes)\".format(elapsed, elapsed / 60) + \n",
    "      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n",
    "      .format(df.shape[0], df.shape[1]) + \n",
    "      \"\\n-- Column names:\\n\", df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6803691 entries, 0 to 6803690\nData columns (total 17 columns):\nlro_num               6803691 non-null int64\npin                   6803691 non-null int64\nconsideration_amt     6803691 non-null float64\nregistration_date     6803691 non-null datetime64[ns]\npostal_code           6233365 non-null object\nunitno                1572959 non-null object\nstreet_name           6598317 non-null object\nstreet_designation    6522418 non-null object\nstreet_direction      683462 non-null object\nmunicipality          6799681 non-null object\nstreet_number         6594324 non-null object\nx                     6803691 non-null float64\ny                     6803691 non-null float64\nobjectid              6803691 non-null int64\ndauid                 6803691 non-null int64\ncsdname               6803691 non-null object\nstreet_name_raw       6598317 non-null object\ndtypes: datetime64[ns](1), float64(3), int64(4), object(9)\nmemory usage: 882.4+ MB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df.info(null_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Surrogate key\n",
    "\n",
    "### Add attribute `transaction_id`\n",
    "Attribute `transaction_id` is intended as a unique identifier for each record in the Teranet dataset. It will be used as the **_primary key_** for records in Teranet table in the proposed GTHA housing market database. It is produced as a surrogate key, as no other attribute or combination of attributes in the Teranet dataset allows the records to be uniquely identified. \n",
    "    \n",
    "`transaction_id` is essentially a simple range index, which represents the row number of a record in the full Teranet dataset (filtered to include only GTHA records), ordered by date (from earliest to latest) and `pin`\n",
    "\n",
    "#### Order Teranet records by `registration_date` and `pin`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "DataFrame was resorted by 'registration_date' and 'pin'.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df = df.sort_values(['registration_date', 'pin'])\n",
    "print(\"DataFrame was resorted by 'registration_date' and 'pin'.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert the new column `transaction_id`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column 'transaction_id' was added to the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df.insert(0, \"transaction_id\", np.arange(len(df)))\n",
    "print(\"New column 'transaction_id' was added to the DataFrame.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attributes for display\n",
    "\n",
    "### Add attribute `date_disp`\n",
    "Since Teranet records do not carry any actual timestamp (each record has a timestamp of '00:00:00'), a new column `date_disp` is created from `registration_date` to show only dates. The new column `date_disp` has a data type of `datetime.date`, while the original column `registration_date` is stored in NumPy's `datetime64` data type, which allows more efficient datetime operations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column 'date_disp' was added to the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df['date_disp'] = df['registration_date'].dt.date\n",
    "print(\"New column 'date_disp' was added to the DataFrame.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add attribute `price_disp`\n",
    "A new column `price_disp` is created from values of `consideration_amt` formatted to include thousands separator (_e.g.,_ '3,455,122') and stored as a string, for display purposes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column 'price_disp' was added to the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df['price_disp'] = df['consideration_amt'].apply(lambda x: '{:,}'.format(x))\n",
    "print(\"New column 'price_disp' was added to the DataFrame.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add attribute `year`\n",
    "The new attribute `year` is parsed from `registration_date` and stored as a string, to simplify record grouping."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column 'year' was added to the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df['year'] = df['date_disp'].astype('str').apply(lambda x: x[:4])\n",
    "print(\"New column 'year' was added to the DataFrame.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add attribute `3year`\n",
    "The new attribute `3year` is created from the column `year` parsed for 3-year intervals (_e.g.,_ '2014-2016') and stored as a string, to simplify record grouping."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column '3year' was added to the DataFrame. Took 326.91 seconds (5.45 minutes).\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "1805-1811         5\n1815-1817         6\n1819-1821         7\n1822-1824         9\n1827-1829        13\n              ...  \n2005-2007    798539\n2008-2010    729790\n2011-2013    760386\n2014-2016    862676\n2017         218843\nName: 3year, Length: 68, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df['3year'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 3:\n",
    "        df['3year'] = df['3year'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$', \n",
    "                                              ylist[0] + '-' + ylist[2])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column '3year' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['3year'].value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add attribute `5year`\n",
    "The new attribute `5year` is created from the column `year` parsed for 5-year intervals (_e.g.,_ '2012-2016') and stored as a string, to simplify record grouping."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column '5year' was added to the DataFrame. Took 195.34 seconds (3.26 minutes).\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "1805               1\n1809-1817         10\n1819-1823         11\n1824-1831         23\n1832-1836         14\n1837-1841         17\n1842-1846         39\n1847-1851        119\n1852-1856        743\n1857-1861        203\n1862-1866        118\n1867-1871        284\n1872-1876        421\n1877-1881        392\n1882-1886        523\n1887-1891        546\n1892-1896        475\n1897-1901        311\n1902-1906       1100\n1907-1911       1087\n1912-1916       1845\n1917-1921       1576\n1922-1926       1909\n1927-1931       2105\n1932-1936       1152\n1937-1941       1737\n1942-1946       2894\n1947-1951       9273\n1952-1956      23820\n1957-1961      36874\n1962-1966      54104\n1967-1971      67278\n1972-1976      91223\n1977-1981     128786\n1982-1986     214310\n1987-1991     450498\n1992-1996     605472\n1997-2001     970776\n2002-2006    1283035\n2007-2011    1267902\n2012-2016    1361842\n2017          218843\nName: 5year, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df['5year'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()[1:] # skipping first year (1805) to match the length of a 5-year window\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        df['5year'] = df['5year'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$|^' +\n",
    "                                              ylist[3] + '$|^' + ylist[4] + '$', \n",
    "                                              ylist[0] + '-' + ylist[4])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column '5year' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['5year'].value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add attribute `10year`\n",
    "The new attribute `10year` is created from the column `year` parsed for 5-year intervals (_e.g.,_ '2014-2017') and stored as a string, to simplify record grouping."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column '10year' was added to the DataFrame. Took 97.64 seconds (1.63 minutes).\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "1805               1\n1809-1823         21\n1824-1836         37\n1837-1846         56\n1847-1856        862\n1857-1866        321\n1867-1876        705\n1877-1886        915\n1887-1896       1021\n1897-1906       1411\n1907-1916       2932\n1917-1926       3485\n1927-1936       3257\n1937-1946       4631\n1947-1956      33093\n1957-1966      90978\n1967-1976     158501\n1977-1986     343096\n1987-1996    1055970\n1997-2006    2253811\n2007-2016    2629744\n2017          218843\nName: 10year, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df['10year'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()[1:] # skipping first year (1805) to match the length of a 10-year window\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        df['10year'] = df['10year'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$|^' +\n",
    "                                                ylist[3] + '$|^' + ylist[4] + '$|^' + ylist[5] + '$|^' + ylist[6] +\n",
    "                                                '$|^' + ylist[7] + '$|^' + ylist[8] + '$|^' + ylist[9] + '$', \n",
    "                                                ylist[0] + '-' + ylist[9])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column '10year' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['10year'].value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add attribute `xy`\n",
    "\n",
    "The new attribute `xy` is produced by concatenating `x` and `y` together (_e.g.,_ '-79.9774202446447_43.203290987723'), it can be used to identify and group records by their coordinate pairs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "New column 'xy' was added to the DataFrame.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df['xy'] = df['x'].astype('str') + '_' + df['y'].astype('str')\n",
    "print(\"New column 'xy' was added to the DataFrame.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correction of `consideration_amt` for inflation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory attributes\n",
    "\n",
    "### Add column `total_sales`\n",
    "Total records for each pin, generated as a separate DataFrame `df_pin` which represents Teranet records grouped and indexed by `pin`.\n",
    "\n",
    "`total_sales_pin` is added as a new column for Teranet records via a merge operation on `pin`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\nNew column 'pin_total_sales' added to the DataFrame!\ntook 24.94 seconds.\n",
      "\nNew column 'xy_total_sales' added to the DataFrame!\ntook 20.06 seconds.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# group records by `pin`\n",
    "t = time()\n",
    "pin_counts = \\\n",
    "    df.groupby('pin')['consideration_amt'].count()\n",
    "pin_counts.name = 'pin_total_sales'\n",
    "df = pd.merge(df, pin_counts, on='pin')\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_total_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group records by `xy` coordinate pairs\n",
    "t = time()\n",
    "xy_counts = \\\n",
    "    df.groupby('xy')['consideration_amt'].count()\n",
    "xy_counts.name = 'xy_total_sales'\n",
    "df = pd.merge(df, xy_counts, on='xy')\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_total_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add column `prev_sales`\n",
    "New columns are added to Teranet records capturing, for each transaction, a rolling count of previous records from this `pin` or `xy` coordinate pair."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\nNew column 'pin_prev_sales' added to the DataFrame!\ntook 13.20 seconds.\n",
      "\nNew column 'xy_prev_sales' added to the DataFrame!\ntook 20.61 seconds.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df['count'] = 1 # used to produce rolling counts per `pin` and `xy`\n",
    "\n",
    "# group by `pin`\n",
    "t = time()\n",
    "df['pin_prev_sales'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['count'].cumsum() - 1\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_prev_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group by xy pairs\n",
    "t = time()\n",
    "df['xy_prev_sales'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['count'].cumsum() - 1\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_prev_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "df = df.drop('count', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add columns `price_cum_sum` and `price_pct_change`\n",
    "New columns are added to Teranet records capturing, for each transaction, a rolling sum of price from previous records from this `pin` or `xy` coordinate pair, and `pct_change` compared to previous transaction from this `pin` or `xy` pair."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\nNew column 'pin_price_cum_sum' added to the DataFrame!\ntook 9.30 seconds.\n",
      "\nNew column 'xy_price_cum_sum' added to the DataFrame!\ntook 20.30 seconds.\n",
      "\nNew column 'pin_price_pct_change' added to the DataFrame!\ntook 10.30 seconds.\n",
      "\nNew column 'xy_price_pct_change' added to the DataFrame!\ntook 21.32 seconds.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# `price_cum_sum`\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df['pin_price_cum_sum'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['consideration_amt'].cumsum()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_price_cum_sum' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# group records by `xy` pairs\n",
    "t = time()\n",
    "df['xy_price_cum_sum'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['consideration_amt'].cumsum()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_price_cum_sum' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# `price_pct_change`\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df['pin_price_pct_change'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_price_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# group records by `xy`\n",
    "t = time()\n",
    "df['xy_price_pct_change'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_price_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add column `price_da_pct_change`\n",
    "New column is added to Teranet records capturing, for each transaction, percentage change in price compared to the previous record from this `da_id`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\nNew column 'price_da_pct_change' added to the DataFrame!\ntook 8.90 seconds.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# add column 'price_da_pct_change' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['price_da_pct_change'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "    .groupby('dauid')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'price_da_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add columns `years_since_last_sale`\n",
    "New columns are added to Teranet records capturing, for each transaction, years passed since the previous record from this `pin` or `xy` coordinate pair."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mcurried_with_axis\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcurried_with_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_with_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: diff() got an unexpected keyword argument 'axis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried_with_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0m_group_selection_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mcurried_with_axis\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcurried_with_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_with_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: diff() got an unexpected keyword argument 'axis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d42a9d666ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pin_years_since_last_sale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'registration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m365\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     @Substitution(\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mcurried\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcurried\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0;31m# preserve the name so we can detect it when calling plot methods,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(self, periods)\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2546\u001b[0m         \"\"\"\n\u001b[0;32m-> 2547\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2548\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(arr, n, axis)\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         out_arr = (\n\u001b[0;32m-> 1983\u001b[0;31m             \u001b[0mTimedeltaIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1984\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0masi8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timedelta64[ns]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/indexes/timedeltas.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, unit, freq, start, end, periods, closed, dtype, copy, name, verify_integrity)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         tdarr = TimedeltaArray._from_sequence(\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtdarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/arrays/timedeltas.py\u001b[0m in \u001b[0;36m_from_sequence\u001b[0;34m(cls, data, dtype, copy, freq, unit)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0m_validate_td64_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_infer_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferred_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_to_td64ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gds/lib/python3.6/site-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36mmaybe_infer_freq\u001b[0;34m(freq)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0;31m# if a passed freq is None, don't infer automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m             \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mfreq_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "t = time()\n",
    "df['pin_years_since_last_sale'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "      .groupby('pin')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'pin_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Adding the new column...\")\n",
    "# add column 'prev_visits' to Teranet records DataFrame \n",
    "t = time.time()\n",
    "df['xy_years_since_last_sale'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "      .groupby('xy')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time.time() - t\n",
    "print(\"New column 'xy_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add columns `da_days_since_last_sale` and `da_years_since_last_sale`\n",
    "New columns are added to Teranet records capturing, for each transaction, years passed since the previous record from this `pin` or `xy` coordinate pair."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Adding new columns...\")\n",
    "# add column 'da_days_since_last_sale' to Teranet records DataFrame \n",
    "t = time.time()\n",
    "df['da_days_since_last_sale'] = \\\n",
    "    df.sort_values(['da_id', 'registration_date'])\\\n",
    "      .groupby('da_id')['registration_date']\\\n",
    "        .diff().dt.days\n",
    "elapsed = time.time() - t\n",
    "print(\"New column 'da_days_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# add column 'da_years_since_last_sale' to Teranet records DataFrame \n",
    "t = time.time()\n",
    "df['da_years_since_last_sale'] = \\\n",
    "    df.sort_values(['da_id', 'registration_date'])\\\n",
    "      .groupby('da_id')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time.time() - t\n",
    "print(\"New column 'da_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add columns `sale_next_6m/1y/3y` per `pin` and `xy`\n",
    "New columns are added to Teranet records capturing, for each transaction, whether there would be another transaction in the future from this `pin`, `xy`, or `da_id`\n",
    "\n",
    "Time horizons used: 6 months, 1 year, 3 years."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Adding new columns...\")\n",
    "\n",
    "# create a new column, marks True if next 'day_diff' <= 5\n",
    "\n",
    "# group records by `pin`\n",
    "t = time.time()\n",
    "df = df.sort_values(['pin', 'registration_date'])\n",
    "df['pin_sale_next_6m'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 0.5\n",
    "df['pin_sale_next_1y'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 1\n",
    "df['pin_sale_next_3y'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 3\n",
    "elapsed = time.time() - t\n",
    "print(\"New columns 'pin_sale_next_..' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group records by `xy`\n",
    "t = time.time()\n",
    "df = df.sort_values(['xy', 'registration_date'])\n",
    "df['xy_sale_next_6m'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 0.5\n",
    "df['xy_sale_next_1y'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 1\n",
    "df['xy_sale_next_3y'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 3\n",
    "elapsed = time.time() - t\n",
    "print(\"New columns 'xy_sale_next_..' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save results to a new .csv file\n",
    "Teranet dataset without NaN records and with 12 new columns is saved as:\n",
    "`data/HHSaleHistory_cleaned_v0.9_GTHA_DA_with_cols_v0.9.csv`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "save_path = 'data/HHSaleHistory_cleaned_v0.9_GTHA_DA_with_cols_v0.9.csv'\n",
    "df.to_csv(save_path, index=False)\n",
    "elapsed = time.time() - t\n",
    "print(\"File saved to path:\\n'\" + save_path + \"'\" + \n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}